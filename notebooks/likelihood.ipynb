{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from bias_helper import BiasHelper\n",
    "\n",
    "bias = BiasHelper('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bias_helper.BiasHelper"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/stitsyuk/IdeaProjects/debias/notebooks/likelihood.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/stitsyuk/IdeaProjects/debias/notebooks/likelihood.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(bias[\u001b[39m0\u001b[39;49m])):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stitsyuk/IdeaProjects/debias/notebooks/likelihood.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(bias[\u001b[39m0\u001b[39m][i])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for i in range(len(bias[0])):\n",
    "    print(bias[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaConfig, RobertaForMaskedLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta = RobertaForMaskedLM.from_pretrained(\"roberta-base\")\n",
    "# tokenizer_large = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
    "# roberta_large = RobertaForMaskedLM.from_pretrained(\"roberta-large\")\n",
    "\n",
    "def predict(sent, word_list, model=roberta, tokenizer=tokenizer):\n",
    "    inputs = tokenizer(sent, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "\n",
    "    likelihood = torch.softmax(logits[0, mask_token_index], dim=1)\n",
    "\n",
    "    likelihoods = [likelihood[0, tokenizer.encode(f\" {word}\")[1]] for word in word_list]\n",
    "\n",
    "    return likelihoods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the likelihoods of words from the democratic pool. Here is the structure of the dictionary:\n",
    "\n",
    "likelihoods = {\n",
    "    \n",
    "        trigger_1: {\n",
    "\n",
    "            democratic_word_1: likelihood\n",
    "            ...\n",
    "        }\n",
    "        ...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "christian\n",
      "[0, 29224, 811, 2]\n",
      "muslim\n",
      "[0, 11721, 10839, 2]\n",
      "lgbt\n",
      "[0, 784, 571, 25933, 2]\n",
      "lgbtq\n",
      "[0, 784, 571, 25933, 1343, 2]\n",
      "jewish\n",
      "[0, 14917, 1173, 2]\n",
      "buddhist\n",
      "[0, 18464, 417, 32001, 2]\n",
      "atheist\n",
      "[0, 41567, 2]\n",
      "hispanic\n",
      "[0, 39, 46067, 2]\n",
      "minor\n",
      "[0, 3694, 2]\n",
      "catholic\n",
      "[0, 31420, 12589, 2]\n"
     ]
    }
   ],
   "source": [
    "# word_list = ['male', 'female', 'man', 'woman', 'he', 'she', 'gentleman', 'lady', 'bisexual', 'transgender']\n",
    "# word_list = ['white', 'black', 'caucasian', 'african', 'european', 'asian', 'american', 'latino', 'indian', 'chinese']\n",
    "word_list = ['christian', 'muslim', 'lgbt', 'lgbtq', 'jewish', 'buddhist', 'atheist', 'hispanic', 'minor', 'catholic']\n",
    "\n",
    "for word in word_list:\n",
    "    print(word)\n",
    "    print(tokenizer.encode(f\" {word}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " christ\n",
      "ian\n",
      " mus\n",
      "lim\n",
      " l\n",
      "g\n",
      "bt\n",
      " jew\n",
      "ish\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(29224))\n",
    "print(tokenizer.decode(811))\n",
    "print(tokenizer.decode(11721))\n",
    "print(tokenizer.decode(10839))\n",
    "print(tokenizer.decode(784))\n",
    "print(tokenizer.decode(571))\n",
    "print(tokenizer.decode(25933))\n",
    "print(tokenizer.decode(14917))\n",
    "print(tokenizer.decode(1173))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/stitsyuk/IdeaProjects/debias/notebooks/likelihood.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stitsyuk/IdeaProjects/debias/notebooks/likelihood.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m trigger \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m15\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stitsyuk/IdeaProjects/debias/notebooks/likelihood.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m template \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/stitsyuk/IdeaProjects/debias/notebooks/likelihood.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mprint\u001b[39m(bias[trigger][\u001b[39m2\u001b[39m][template])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stitsyuk/IdeaProjects/debias/notebooks/likelihood.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mprint\u001b[39m(bias[trigger][\u001b[39m3\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stitsyuk/IdeaProjects/debias/notebooks/likelihood.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m# print(f\"{predict(bias[trigger][2][template], bias[trigger][3]):.10f}\")\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "likelihoods = {}\n",
    "triggers = {}\n",
    "\n",
    "for trigger in range(15):\n",
    "    for template in range(2):\n",
    "        print(bias[trigger][2][template])\n",
    "        print(bias[trigger][3])\n",
    "        # print(f\"{predict(bias[trigger][2][template], bias[trigger][3]):.10f}\")\n",
    "        print(predict(bias[trigger][2][template], bias[trigger][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
